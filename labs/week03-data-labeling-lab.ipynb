{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 3 Lab: Data Labeling & Annotation\n",
    "\n",
    "**CS 203: Software Tools and Techniques for AI**  \n",
    "**IIT Gandhinagar**\n",
    "\n",
    "---\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this lab, you will be able to:\n",
    "\n",
    "1. Set up and use Label Studio for annotation tasks\n",
    "2. Create annotation interfaces for different data types\n",
    "3. Write clear annotation guidelines\n",
    "4. Calculate Inter-Annotator Agreement (IAA) metrics\n",
    "5. Apply Cohen's Kappa and Fleiss' Kappa to measure label quality\n",
    "6. Calculate IoU for spatial annotations\n",
    "\n",
    "---\n",
    "\n",
    "## Netflix Movie Theme\n",
    "\n",
    "Continuing from Weeks 1-2, we'll label our cleaned movie reviews for sentiment analysis. This labeled data will be used for model training in later weeks.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Environment Setup\n",
    "\n",
    "### 1.1 Install Required Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: label-studio in c:\\projects\\ml_learn\\end-to-end-projects\\ai_og\\.venv\\lib\\site-packages (1.22.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\projects\\ml_learn\\end-to-end-projects\\ai_og\\.venv\\lib\\site-packages (1.8.0)\n",
      "Collecting statsmodels\n",
      "  Downloading statsmodels-0.14.6-cp312-cp312-win_amd64.whl.metadata (9.8 kB)\n",
      "Requirement already satisfied: pandas in c:\\projects\\ml_learn\\end-to-end-projects\\ai_og\\.venv\\lib\\site-packages (2.3.3)\n",
      "Requirement already satisfied: numpy in c:\\projects\\ml_learn\\end-to-end-projects\\ai_og\\.venv\\lib\\site-packages (2.4.1)\n",
      "Requirement already satisfied: matplotlib in c:\\projects\\ml_learn\\end-to-end-projects\\ai_og\\.venv\\lib\\site-packages (3.10.8)\n",
      "Collecting seaborn\n",
      "  Using cached seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: Django<5.2.0,>=5.1.8 in c:\\projects\\ml_learn\\end-to-end-projects\\ai_og\\.venv\\lib\\site-packages (from label-studio) (5.1.15)\n",
      "Requirement already satisfied: appdirs>=1.4.3 in c:\\projects\\ml_learn\\end-to-end-projects\\ai_og\\.venv\\lib\\site-packages (from label-studio) (1.4.4)\n",
      "Requirement already satisfied: attr==0.3.1 in c:\\projects\\ml_learn\\end-to-end-projects\\ai_og\\.venv\\lib\\site-packages (from label-studio) (0.3.1)\n",
      "Requirement already satisfied: attrs>=19.2.0 in c:\\projects\\ml_learn\\end-to-end-projects\\ai_og\\.venv\\lib\\site-packages (from label-studio) (25.4.0)\n",
      "Requirement already satisfied: azure-storage-blob>=12.6.0 in c:\\projects\\ml_learn\\end-to-end-projects\\ai_og\\.venv\\lib\\site-packages (from label-studio) (12.28.0)\n",
      "Requirement already satisfied: bleach<5.1.0,>=5.0.0 in c:\\projects\\ml_learn\\end-to-end-projects\\ai_og\\.venv\\lib\\site-packages (from label-studio) (5.0.1)\n",
      "Requirement already satisfied: boto3<2.0.0,>=1.28.58 in c:\\projects\\ml_learn\\end-to-end-projects\\ai_og\\.venv\\lib\\site-packages (from label-studio) (1.42.30)\n",
      "Requirement already satisfied: botocore<2.0.0,>=1.39.3 in c:\\projects\\ml_learn\\end-to-end-projects\\ai_og\\.venv\\lib\\site-packages (from label-studio) (1.42.30)\n",
      "Requirement already satisfied: colorama>=0.4.4 in c:\\projects\\ml_learn\\end-to-end-projects\\ai_og\\.venv\\lib\\site-packages (from label-studio) (0.4.6)\n",
      "Requirement already satisfied: cryptography>=44.0.1 in c:\\projects\\ml_learn\\end-to-end-projects\\ai_og\\.venv\\lib\\site-packages (from label-studio) (46.0.3)\n",
      "Requirement already satisfied: defusedxml>=0.7.1 in c:\\projects\\ml_learn\\end-to-end-projects\\ai_og\\.venv\\lib\\site-packages (from label-studio) (0.7.1)\n",
      "Requirement already satisfied: django-annoying==0.10.6 in c:\\projects\\ml_learn\\end-to-end-projects\\ai_og\\.venv\\lib\\site-packages (from label-studio) (0.10.6)\n",
      "Requirement already satisfied: django-cors-headers==4.7.0 in c:\\projects\\ml_learn\\end-to-end-projects\\ai_og\\.venv\\lib\\site-packages (from label-studio) (4.7.0)\n",
      "Requirement already satisfied: django-csp==3.7 in c:\\projects\\ml_learn\\end-to-end-projects\\ai_og\\.venv\\lib\\site-packages (from label-studio) (3.7)\n",
      "Requirement already satisfied: django-debug-toolbar==3.2.1 in c:\\projects\\ml_learn\\end-to-end-projects\\ai_og\\.venv\\lib\\site-packages (from label-studio) (3.2.1)\n",
      "Requirement already satisfied: django-environ==0.10.0 in c:\\projects\\ml_learn\\end-to-end-projects\\ai_og\\.venv\\lib\\site-packages (from label-studio) (0.10.0)\n",
      "Requirement already satisfied: django-extensions==3.2.3 in c:\\projects\\ml_learn\\end-to-end-projects\\ai_og\\.venv\\lib\\site-packages (from label-studio) (3.2.3)\n",
      "Requirement already satisfied: django-filter==24.3 in c:\\projects\\ml_learn\\end-to-end-projects\\ai_og\\.venv\\lib\\site-packages (from label-studio) (24.3)\n",
      "Requirement already satisfied: django-migration-linter<6.0.0,>=5.1.0 in c:\\projects\\ml_learn\\end-to-end-projects\\ai_og\\.venv\\lib\\site-packages (from label-studio) (5.2.0)\n",
      "Requirement already satisfied: django-model-utils==4.1.1 in c:\\projects\\ml_learn\\end-to-end-projects\\ai_og\\.venv\\lib\\site-packages (from label-studio) (4.1.1)\n",
      "Requirement already satisfied: django-ranged-fileresponse>=0.1.2 in c:\\projects\\ml_learn\\end-to-end-projects\\ai_og\\.venv\\lib\\site-packages (from label-studio) (0.1.2)\n",
      "Requirement already satisfied: django-rq<3.2,>=3.1 in c:\\projects\\ml_learn\\end-to-end-projects\\ai_og\\.venv\\lib\\site-packages (from label-studio) (3.1)\n",
      "Requirement already satisfied: django-storages==1.12.3 in c:\\projects\\ml_learn\\end-to-end-projects\\ai_og\\.venv\\lib\\site-packages (from label-studio) (1.12.3)\n",
      "Requirement already satisfied: django-user-agents==0.4.0 in c:\\projects\\ml_learn\\end-to-end-projects\\ai_og\\.venv\\lib\\site-packages (from label-studio) (0.4.0)\n",
      "Requirement already satisfied: djangorestframework==3.15.2 in c:\\projects\\ml_learn\\end-to-end-projects\\ai_og\\.venv\\lib\\site-packages (from label-studio) (3.15.2)\n",
      "Requirement already satisfied: djangorestframework-simplejwt<6.0.0,>=5.4.0 in c:\\projects\\ml_learn\\end-to-end-projects\\ai_og\\.venv\\lib\\site-packages (from djangorestframework-simplejwt[crypto]<6.0.0,>=5.4.0->label-studio) (5.5.1)\n",
      "Requirement already satisfied: drf-dynamic-fields==0.3.0 in c:\\projects\\ml_learn\\end-to-end-projects\\ai_og\\.venv\\lib\\site-packages (from label-studio) (0.3.0)\n",
      "Requirement already satisfied: drf-flex-fields==0.9.5 in c:\\projects\\ml_learn\\end-to-end-projects\\ai_og\\.venv\\lib\\site-packages (from label-studio) (0.9.5)\n",
      "Requirement already satisfied: drf-generators==0.3.0 in c:\\projects\\ml_learn\\end-to-end-projects\\ai_og\\.venv\\lib\\site-packages (from label-studio) (0.3.0)\n",
      "Requirement already satisfied: drf-spectacular==0.28.0 in c:\\projects\\ml_learn\\end-to-end-projects\\ai_og\\.venv\\lib\\site-packages (from label-studio) (0.28.0)\n",
      "Requirement already satisfied: google-cloud-logging<4.0.0,>=3.10.0 in c:\\projects\\ml_learn\\end-to-end-projects\\ai_og\\.venv\\lib\\site-packages (from label-studio) (3.13.0)\n",
      "Requirement already satisfied: google-cloud-storage<3.0.0,>=2.13.0 in c:\\projects\\ml_learn\\end-to-end-projects\\ai_og\\.venv\\lib\\site-packages (from label-studio) (2.19.0)\n",
      "Requirement already satisfied: ijson<4.0.0,>=3.4.0 in c:\\projects\\ml_learn\\end-to-end-projects\\ai_og\\.venv\\lib\\site-packages (from label-studio) (3.4.0.post0)\n",
      "Requirement already satisfied: label-studio-sdk==2.0.16 in c:\\projects\\ml_learn\\end-to-end-projects\\ai_og\\.venv\\lib\\site-packages (from label-studio) (2.0.16)\n",
      "Requirement already satisfied: launchdarkly-server-sdk==8.2.1 in c:\\projects\\ml_learn\\end-to-end-projects\\ai_og\\.venv\\lib\\site-packages (from label-studio) (8.2.1)\n",
      "Requirement already satisfied: lockfile>=0.12.0 in c:\\projects\\ml_learn\\end-to-end-projects\\ai_og\\.venv\\lib\\site-packages (from label-studio) (0.12.2)\n",
      "Requirement already satisfied: lxml>=4.9.4 in c:\\projects\\ml_learn\\end-to-end-projects\\ai_og\\.venv\\lib\\site-packages (from lxml[html-clean]>=4.9.4->label-studio) (6.0.2)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.10.0 in c:\\projects\\ml_learn\\end-to-end-projects\\ai_og\\.venv\\lib\\site-packages (from label-studio) (1.109.1)\n",
      "Requirement already satisfied: ordered-set==4.0.2 in c:\\projects\\ml_learn\\end-to-end-projects\\ai_og\\.venv\\lib\\site-packages (from label-studio) (4.0.2)\n",
      "Requirement already satisfied: psycopg<4.0.0,>=3.2.0 in c:\\projects\\ml_learn\\end-to-end-projects\\ai_og\\.venv\\lib\\site-packages (from psycopg[binary]<4.0.0,>=3.2.0->label-studio) (3.3.2)\n",
      "Requirement already satisfied: pyarrow<23.0.0,>=22.0.0 in c:\\projects\\ml_learn\\end-to-end-projects\\ai_og\\.venv\\lib\\site-packages (from label-studio) (22.0.0)\n",
      "Requirement already satisfied: pyboxen>=1.3.0 in c:\\projects\\ml_learn\\end-to-end-projects\\ai_og\\.venv\\lib\\site-packages (from label-studio) (1.3.0)\n",
      "Requirement already satisfied: pydantic>=2.9.2 in c:\\projects\\ml_learn\\end-to-end-projects\\ai_og\\.venv\\lib\\site-packages (from label-studio) (2.12.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\projects\\ml_learn\\end-to-end-projects\\ai_og\\.venv\\lib\\site-packages (from label-studio) (2.9.0.post0)\n",
      "Requirement already satisfied: python-json-logger==2.0.4 in c:\\projects\\ml_learn\\end-to-end-projects\\ai_og\\.venv\\lib\\site-packages (from label-studio) (2.0.4)\n",
      "Requirement already satisfied: pytz<2023.0,>=2022.1 in c:\\projects\\ml_learn\\end-to-end-projects\\ai_og\\.venv\\lib\\site-packages (from label-studio) (2022.7.1)\n",
      "Requirement already satisfied: pyyaml>=6.0.0 in c:\\projects\\ml_learn\\end-to-end-projects\\ai_og\\.venv\\lib\\site-packages (from label-studio) (6.0.3)\n",
      "Requirement already satisfied: redis<5.3.0,>=5.2.1 in c:\\projects\\ml_learn\\end-to-end-projects\\ai_og\\.venv\\lib\\site-packages (from label-studio) (5.2.1)\n",
      "Requirement already satisfied: requests<2.33.0,>=2.32.3 in c:\\projects\\ml_learn\\end-to-end-projects\\ai_og\\.venv\\lib\\site-packages (from label-studio) (2.32.5)\n",
      "Requirement already satisfied: rq<2.7,>=2.6 in c:\\projects\\ml_learn\\end-to-end-projects\\ai_og\\.venv\\lib\\site-packages (from label-studio) (2.6.1)\n",
      "Requirement already satisfied: rules==3.4 in c:\\projects\\ml_learn\\end-to-end-projects\\ai_og\\.venv\\lib\\site-packages (from label-studio) (3.4)\n",
      "Requirement already satisfied: sentry-sdk>=2.16.0 in c:\\projects\\ml_learn\\end-to-end-projects\\ai_og\\.venv\\lib\\site-packages (from label-studio) (2.49.0)\n",
      "Requirement already satisfied: setuptools>=75.4.0 in c:\\projects\\ml_learn\\end-to-end-projects\\ai_og\\.venv\\lib\\site-packages (from label-studio) (80.9.0)\n",
      "Requirement already satisfied: tldextract>=5.1.3 in c:\\projects\\ml_learn\\end-to-end-projects\\ai_og\\.venv\\lib\\site-packages (from label-studio) (5.3.1)\n",
      "Requirement already satisfied: ujson>=3.0.0 in c:\\projects\\ml_learn\\end-to-end-projects\\ai_og\\.venv\\lib\\site-packages (from label-studio) (5.11.0)\n",
      "Requirement already satisfied: uuid-utils<1.0.0,>=0.11.0 in c:\\projects\\ml_learn\\end-to-end-projects\\ai_og\\.venv\\lib\\site-packages (from label-studio) (0.13.0)\n",
      "Requirement already satisfied: wheel<=0.40.0,>=0.38.1 in c:\\projects\\ml_learn\\end-to-end-projects\\ai_og\\.venv\\lib\\site-packages (from label-studio) (0.40.0)\n",
      "Requirement already satisfied: xmljson==0.2.1 in c:\\projects\\ml_learn\\end-to-end-projects\\ai_og\\.venv\\lib\\site-packages (from label-studio) (0.2.1)\n",
      "Requirement already satisfied: six in c:\\projects\\ml_learn\\end-to-end-projects\\ai_og\\.venv\\lib\\site-packages (from django-annoying==0.10.6->label-studio) (1.17.0)\n",
      "Requirement already satisfied: asgiref>=3.6 in c:\\projects\\ml_learn\\end-to-end-projects\\ai_og\\.venv\\lib\\site-packages (from django-cors-headers==4.7.0->label-studio) (3.11.0)\n",
      "Requirement already satisfied: sqlparse>=0.2.0 in c:\\projects\\ml_learn\\end-to-end-projects\\ai_og\\.venv\\lib\\site-packages (from django-debug-toolbar==3.2.1->label-studio) (0.5.5)\n",
      "Requirement already satisfied: user-agents in c:\\projects\\ml_learn\\end-to-end-projects\\ai_og\\.venv\\lib\\site-packages (from django-user-agents==0.4.0->label-studio) (2.2.0)\n",
      "Requirement already satisfied: uritemplate>=2.0.0 in c:\\projects\\ml_learn\\end-to-end-projects\\ai_og\\.venv\\lib\\site-packages (from drf-spectacular==0.28.0->label-studio) (4.2.0)\n",
      "Requirement already satisfied: jsonschema>=2.6.0 in c:\\projects\\ml_learn\\end-to-end-projects\\ai_og\\.venv\\lib\\site-packages (from drf-spectacular==0.28.0->label-studio) (4.26.0)\n",
      "Requirement already satisfied: inflection>=0.3.1 in c:\\projects\\ml_learn\\end-to-end-projects\\ai_og\\.venv\\lib\\site-packages (from drf-spectacular==0.28.0->label-studio) (0.5.1)\n",
      "Requirement already satisfied: Pillow>=11.3.0 in c:\\projects\\ml_learn\\end-to-end-projects\\ai_og\\.venv\\lib\\site-packages (from label-studio-sdk==2.0.16->label-studio) (12.1.0)\n",
      "Requirement already satisfied: datamodel-code-generator==0.26.1 in c:\\projects\\ml_learn\\end-to-end-projects\\ai_og\\.venv\\lib\\site-packages (from label-studio-sdk==2.0.16->label-studio) (0.26.1)\n",
      "Requirement already satisfied: httpx>=0.21.2 in c:\\projects\\ml_learn\\end-to-end-projects\\ai_og\\.venv\\lib\\site-packages (from label-studio-sdk==2.0.16->label-studio) (0.28.1)\n",
      "Requirement already satisfied: jsf<0.12.0,>=0.11.2 in c:\\projects\\ml_learn\\end-to-end-projects\\ai_og\\.venv\\lib\\site-packages (from label-studio-sdk==2.0.16->label-studio) (0.11.2)\n",
      "Requirement already satisfied: nltk<4.0.0,>=3.9.1 in c:\\projects\\ml_learn\\end-to-end-projects\\ai_og\\.venv\\lib\\site-packages (from label-studio-sdk==2.0.16->label-studio) (3.9.2)\n",
      "Requirement already satisfied: opencv-python-headless<5.0.0,>=4.12.0 in c:\\projects\\ml_learn\\end-to-end-projects\\ai_og\\.venv\\lib\\site-packages (from label-studio-sdk==2.0.16->label-studio) (4.13.0.90)\n",
      "Requirement already satisfied: pydantic-core<3.0.0,>=2.18.2 in c:\\projects\\ml_learn\\end-to-end-projects\\ai_og\\.venv\\lib\\site-packages (from label-studio-sdk==2.0.16->label-studio) (2.41.5)\n",
      "Requirement already satisfied: pyjwt<3.0.0,>=2.10.1 in c:\\projects\\ml_learn\\end-to-end-projects\\ai_og\\.venv\\lib\\site-packages (from label-studio-sdk==2.0.16->label-studio) (2.10.1)\n",
      "Requirement already satisfied: requests-mock==1.12.1 in c:\\projects\\ml_learn\\end-to-end-projects\\ai_og\\.venv\\lib\\site-packages (from label-studio-sdk==2.0.16->label-studio) (1.12.1)\n",
      "Requirement already satisfied: typing_extensions>=4.0.0 in c:\\projects\\ml_learn\\end-to-end-projects\\ai_og\\.venv\\lib\\site-packages (from label-studio-sdk==2.0.16->label-studio) (4.15.0)\n",
      "Requirement already satisfied: urllib3>=2.5.0 in c:\\projects\\ml_learn\\end-to-end-projects\\ai_og\\.venv\\lib\\site-packages (from label-studio-sdk==2.0.16->label-studio) (2.6.3)\n",
      "Requirement already satisfied: argcomplete<4.0,>=1.10 in c:\\projects\\ml_learn\\end-to-end-projects\\ai_og\\.venv\\lib\\site-packages (from datamodel-code-generator==0.26.1->label-studio-sdk==2.0.16->label-studio) (3.6.3)\n",
      "Requirement already satisfied: black>=19.10b0 in c:\\projects\\ml_learn\\end-to-end-projects\\ai_og\\.venv\\lib\\site-packages (from datamodel-code-generator==0.26.1->label-studio-sdk==2.0.16->label-studio) (26.1.0)\n",
      "Requirement already satisfied: genson<2.0,>=1.2.1 in c:\\projects\\ml_learn\\end-to-end-projects\\ai_og\\.venv\\lib\\site-packages (from datamodel-code-generator==0.26.1->label-studio-sdk==2.0.16->label-studio) (1.3.0)\n",
      "Requirement already satisfied: inflect<6.0,>=4.1.0 in c:\\projects\\ml_learn\\end-to-end-projects\\ai_og\\.venv\\lib\\site-packages (from datamodel-code-generator==0.26.1->label-studio-sdk==2.0.16->label-studio) (5.6.2)\n",
      "Requirement already satisfied: isort<6.0,>=4.3.21 in c:\\projects\\ml_learn\\end-to-end-projects\\ai_og\\.venv\\lib\\site-packages (from datamodel-code-generator==0.26.1->label-studio-sdk==2.0.16->label-studio) (5.13.2)\n",
      "Requirement already satisfied: jinja2<4.0,>=2.10.1 in c:\\projects\\ml_learn\\end-to-end-projects\\ai_og\\.venv\\lib\\site-packages (from datamodel-code-generator==0.26.1->label-studio-sdk==2.0.16->label-studio) (3.1.6)\n",
      "Requirement already satisfied: packaging in c:\\projects\\ml_learn\\end-to-end-projects\\ai_og\\.venv\\lib\\site-packages (from datamodel-code-generator==0.26.1->label-studio-sdk==2.0.16->label-studio) (25.0)\n",
      "Requirement already satisfied: certifi>=2018.4.16 in c:\\projects\\ml_learn\\end-to-end-projects\\ai_og\\.venv\\lib\\site-packages (from launchdarkly-server-sdk==8.2.1->label-studio) (2026.1.4)\n",
      "Requirement already satisfied: expiringdict>=1.1.4 in c:\\projects\\ml_learn\\end-to-end-projects\\ai_og\\.venv\\lib\\site-packages (from launchdarkly-server-sdk==8.2.1->label-studio) (1.2.2)\n",
      "Requirement already satisfied: pyRFC3339>=1.0 in c:\\projects\\ml_learn\\end-to-end-projects\\ai_og\\.venv\\lib\\site-packages (from launchdarkly-server-sdk==8.2.1->label-studio) (2.1.0)\n",
      "Requirement already satisfied: semver>=2.10.2 in c:\\projects\\ml_learn\\end-to-end-projects\\ai_og\\.venv\\lib\\site-packages (from launchdarkly-server-sdk==8.2.1->label-studio) (3.0.4)\n",
      "Requirement already satisfied: webencodings in c:\\projects\\ml_learn\\end-to-end-projects\\ai_og\\.venv\\lib\\site-packages (from bleach<5.1.0,>=5.0.0->label-studio) (0.5.1)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in c:\\projects\\ml_learn\\end-to-end-projects\\ai_og\\.venv\\lib\\site-packages (from boto3<2.0.0,>=1.28.58->label-studio) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.17.0,>=0.16.0 in c:\\projects\\ml_learn\\end-to-end-projects\\ai_og\\.venv\\lib\\site-packages (from boto3<2.0.0,>=1.28.58->label-studio) (0.16.0)\n",
      "Requirement already satisfied: tzdata in c:\\projects\\ml_learn\\end-to-end-projects\\ai_og\\.venv\\lib\\site-packages (from Django<5.2.0,>=5.1.8->label-studio) (2025.3)\n",
      "Requirement already satisfied: toml>=0.10.2 in c:\\projects\\ml_learn\\end-to-end-projects\\ai_og\\.venv\\lib\\site-packages (from django-migration-linter<6.0.0,>=5.1.0->label-studio) (0.10.2)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1 in c:\\projects\\ml_learn\\end-to-end-projects\\ai_og\\.venv\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-cloud-logging<4.0.0,>=3.10.0->label-studio) (2.29.0)\n",
      "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1 in c:\\projects\\ml_learn\\end-to-end-projects\\ai_og\\.venv\\lib\\site-packages (from google-cloud-logging<4.0.0,>=3.10.0->label-studio) (2.47.0)\n",
      "Requirement already satisfied: google-cloud-appengine-logging<2.0.0,>=0.1.3 in c:\\projects\\ml_learn\\end-to-end-projects\\ai_og\\.venv\\lib\\site-packages (from google-cloud-logging<4.0.0,>=3.10.0->label-studio) (1.8.0)\n",
      "Requirement already satisfied: google-cloud-audit-log<1.0.0,>=0.3.1 in c:\\projects\\ml_learn\\end-to-end-projects\\ai_og\\.venv\\lib\\site-packages (from google-cloud-logging<4.0.0,>=3.10.0->label-studio) (0.4.0)\n",
      "Requirement already satisfied: google-cloud-core<3.0.0,>=2.0.0 in c:\\projects\\ml_learn\\end-to-end-projects\\ai_og\\.venv\\lib\\site-packages (from google-cloud-logging<4.0.0,>=3.10.0->label-studio) (2.5.0)\n",
      "Requirement already satisfied: grpc-google-iam-v1<1.0.0,>=0.12.4 in c:\\projects\\ml_learn\\end-to-end-projects\\ai_og\\.venv\\lib\\site-packages (from google-cloud-logging<4.0.0,>=3.10.0->label-studio) (0.14.3)\n",
      "Requirement already satisfied: opentelemetry-api>=1.9.0 in c:\\projects\\ml_learn\\end-to-end-projects\\ai_og\\.venv\\lib\\site-packages (from google-cloud-logging<4.0.0,>=3.10.0->label-studio) (1.39.1)\n",
      "Requirement already satisfied: proto-plus<2.0.0,>=1.22.0 in c:\\projects\\ml_learn\\end-to-end-projects\\ai_og\\.venv\\lib\\site-packages (from google-cloud-logging<4.0.0,>=3.10.0->label-studio) (1.27.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in c:\\projects\\ml_learn\\end-to-end-projects\\ai_og\\.venv\\lib\\site-packages (from google-cloud-logging<4.0.0,>=3.10.0->label-studio) (6.33.4)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in c:\\projects\\ml_learn\\end-to-end-projects\\ai_og\\.venv\\lib\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-cloud-logging<4.0.0,>=3.10.0->label-studio) (1.72.0)\n",
      "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in c:\\projects\\ml_learn\\end-to-end-projects\\ai_og\\.venv\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-cloud-logging<4.0.0,>=3.10.0->label-studio) (1.76.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in c:\\projects\\ml_learn\\end-to-end-projects\\ai_og\\.venv\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-cloud-logging<4.0.0,>=3.10.0->label-studio) (1.76.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\projects\\ml_learn\\end-to-end-projects\\ai_og\\.venv\\lib\\site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-cloud-logging<4.0.0,>=3.10.0->label-studio) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\projects\\ml_learn\\end-to-end-projects\\ai_og\\.venv\\lib\\site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-cloud-logging<4.0.0,>=3.10.0->label-studio) (4.9.1)\n",
      "Requirement already satisfied: google-resumable-media>=2.7.2 in c:\\projects\\ml_learn\\end-to-end-projects\\ai_og\\.venv\\lib\\site-packages (from google-cloud-storage<3.0.0,>=2.13.0->label-studio) (2.8.0)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in c:\\projects\\ml_learn\\end-to-end-projects\\ai_og\\.venv\\lib\\site-packages (from google-cloud-storage<3.0.0,>=2.13.0->label-studio) (1.8.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\projects\\ml_learn\\end-to-end-projects\\ai_og\\.venv\\lib\\site-packages (from jinja2<4.0,>=2.10.1->datamodel-code-generator==0.26.1->label-studio-sdk==2.0.16->label-studio) (3.0.3)\n",
      "Requirement already satisfied: faker>=15.3.4 in c:\\projects\\ml_learn\\end-to-end-projects\\ai_og\\.venv\\lib\\site-packages (from jsf<0.12.0,>=0.11.2->label-studio-sdk==2.0.16->label-studio) (40.1.2)\n",
      "Requirement already satisfied: rstr>=3.2.0 in c:\\projects\\ml_learn\\end-to-end-projects\\ai_og\\.venv\\lib\\site-packages (from jsf<0.12.0,>=0.11.2->label-studio-sdk==2.0.16->label-studio) (3.2.2)\n",
      "Requirement already satisfied: smart-open>=6.3.0 in c:\\projects\\ml_learn\\end-to-end-projects\\ai_og\\.venv\\lib\\site-packages (from smart-open[http]>=6.3.0->jsf<0.12.0,>=0.11.2->label-studio-sdk==2.0.16->label-studio) (7.5.0)\n",
      "Requirement already satisfied: click in c:\\projects\\ml_learn\\end-to-end-projects\\ai_og\\.venv\\lib\\site-packages (from nltk<4.0.0,>=3.9.1->label-studio-sdk==2.0.16->label-studio) (8.3.1)\n",
      "Requirement already satisfied: joblib in c:\\projects\\ml_learn\\end-to-end-projects\\ai_og\\.venv\\lib\\site-packages (from nltk<4.0.0,>=3.9.1->label-studio-sdk==2.0.16->label-studio) (1.5.3)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\projects\\ml_learn\\end-to-end-projects\\ai_og\\.venv\\lib\\site-packages (from nltk<4.0.0,>=3.9.1->label-studio-sdk==2.0.16->label-studio) (2026.1.15)\n",
      "Requirement already satisfied: tqdm in c:\\projects\\ml_learn\\end-to-end-projects\\ai_og\\.venv\\lib\\site-packages (from nltk<4.0.0,>=3.9.1->label-studio-sdk==2.0.16->label-studio) (4.67.1)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\projects\\ml_learn\\end-to-end-projects\\ai_og\\.venv\\lib\\site-packages (from openai<2.0.0,>=1.10.0->label-studio) (4.12.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\projects\\ml_learn\\end-to-end-projects\\ai_og\\.venv\\lib\\site-packages (from openai<2.0.0,>=1.10.0->label-studio) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\projects\\ml_learn\\end-to-end-projects\\ai_og\\.venv\\lib\\site-packages (from openai<2.0.0,>=1.10.0->label-studio) (0.12.0)\n",
      "Requirement already satisfied: sniffio in c:\\projects\\ml_learn\\end-to-end-projects\\ai_og\\.venv\\lib\\site-packages (from openai<2.0.0,>=1.10.0->label-studio) (1.3.1)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\projects\\ml_learn\\end-to-end-projects\\ai_og\\.venv\\lib\\site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.10.0->label-studio) (3.11)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\projects\\ml_learn\\end-to-end-projects\\ai_og\\.venv\\lib\\site-packages (from httpx>=0.21.2->label-studio-sdk==2.0.16->label-studio) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\projects\\ml_learn\\end-to-end-projects\\ai_og\\.venv\\lib\\site-packages (from httpcore==1.*->httpx>=0.21.2->label-studio-sdk==2.0.16->label-studio) (0.16.0)\n",
      "Requirement already satisfied: psycopg-binary==3.3.2 in c:\\projects\\ml_learn\\end-to-end-projects\\ai_og\\.venv\\lib\\site-packages (from psycopg[binary]<4.0.0,>=3.2.0->label-studio) (3.3.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\projects\\ml_learn\\end-to-end-projects\\ai_og\\.venv\\lib\\site-packages (from pydantic>=2.9.2->label-studio) (0.7.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in c:\\projects\\ml_learn\\end-to-end-projects\\ai_og\\.venv\\lib\\site-packages (from pydantic>=2.9.2->label-studio) (0.4.2)\n",
      "Requirement already satisfied: email-validator>=2.0.0 in c:\\projects\\ml_learn\\end-to-end-projects\\ai_og\\.venv\\lib\\site-packages (from pydantic[email]!=2.0.0,!=2.0.1,!=2.4.0,<3.0,>=1.10.0; python_version >= \"3.12\" and python_version < \"4.0\"->datamodel-code-generator==0.26.1->label-studio-sdk==2.0.16->label-studio) (2.3.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\projects\\ml_learn\\end-to-end-projects\\ai_og\\.venv\\lib\\site-packages (from requests<2.33.0,>=2.32.3->label-studio) (3.4.4)\n",
      "Requirement already satisfied: croniter in c:\\projects\\ml_learn\\end-to-end-projects\\ai_og\\.venv\\lib\\site-packages (from rq<2.7,>=2.6->label-studio) (6.0.0)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in c:\\projects\\ml_learn\\end-to-end-projects\\ai_og\\.venv\\lib\\site-packages (from rsa<5,>=3.1.4->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-cloud-logging<4.0.0,>=3.10.0->label-studio) (0.6.2)\n",
      "Requirement already satisfied: scipy>=1.10.0 in c:\\projects\\ml_learn\\end-to-end-projects\\ai_og\\.venv\\lib\\site-packages (from scikit-learn) (1.17.0)\n",
      "Requirement already satisfied: threadpoolctl>=3.2.0 in c:\\projects\\ml_learn\\end-to-end-projects\\ai_og\\.venv\\lib\\site-packages (from scikit-learn) (3.6.0)\n",
      "Collecting patsy>=0.5.6 (from statsmodels)\n",
      "  Using cached patsy-1.0.2-py2.py3-none-any.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\projects\\ml_learn\\end-to-end-projects\\ai_og\\.venv\\lib\\site-packages (from matplotlib) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\projects\\ml_learn\\end-to-end-projects\\ai_og\\.venv\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\projects\\ml_learn\\end-to-end-projects\\ai_og\\.venv\\lib\\site-packages (from matplotlib) (4.61.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\projects\\ml_learn\\end-to-end-projects\\ai_og\\.venv\\lib\\site-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: pyparsing>=3 in c:\\projects\\ml_learn\\end-to-end-projects\\ai_og\\.venv\\lib\\site-packages (from matplotlib) (3.3.1)\n",
      "Requirement already satisfied: azure-core>=1.30.0 in c:\\projects\\ml_learn\\end-to-end-projects\\ai_og\\.venv\\lib\\site-packages (from azure-storage-blob>=12.6.0->label-studio) (1.38.0)\n",
      "Requirement already satisfied: isodate>=0.6.1 in c:\\projects\\ml_learn\\end-to-end-projects\\ai_og\\.venv\\lib\\site-packages (from azure-storage-blob>=12.6.0->label-studio) (0.7.2)\n",
      "Requirement already satisfied: mypy-extensions>=0.4.3 in c:\\projects\\ml_learn\\end-to-end-projects\\ai_og\\.venv\\lib\\site-packages (from black>=19.10b0->datamodel-code-generator==0.26.1->label-studio-sdk==2.0.16->label-studio) (1.1.0)\n",
      "Requirement already satisfied: pathspec>=1.0.0 in c:\\projects\\ml_learn\\end-to-end-projects\\ai_og\\.venv\\lib\\site-packages (from black>=19.10b0->datamodel-code-generator==0.26.1->label-studio-sdk==2.0.16->label-studio) (1.0.3)\n",
      "Requirement already satisfied: platformdirs>=2 in c:\\projects\\ml_learn\\end-to-end-projects\\ai_og\\.venv\\lib\\site-packages (from black>=19.10b0->datamodel-code-generator==0.26.1->label-studio-sdk==2.0.16->label-studio) (4.5.1)\n",
      "Requirement already satisfied: pytokens>=0.3.0 in c:\\projects\\ml_learn\\end-to-end-projects\\ai_og\\.venv\\lib\\site-packages (from black>=19.10b0->datamodel-code-generator==0.26.1->label-studio-sdk==2.0.16->label-studio) (0.4.0)\n",
      "Requirement already satisfied: cffi>=2.0.0 in c:\\projects\\ml_learn\\end-to-end-projects\\ai_og\\.venv\\lib\\site-packages (from cryptography>=44.0.1->label-studio) (2.0.0)\n",
      "Requirement already satisfied: pycparser in c:\\projects\\ml_learn\\end-to-end-projects\\ai_og\\.venv\\lib\\site-packages (from cffi>=2.0.0->cryptography>=44.0.1->label-studio) (2.23)\n",
      "Requirement already satisfied: dnspython>=2.0.0 in c:\\projects\\ml_learn\\end-to-end-projects\\ai_og\\.venv\\lib\\site-packages (from email-validator>=2.0.0->pydantic[email]!=2.0.0,!=2.0.1,!=2.4.0,<3.0,>=1.10.0; python_version >= \"3.12\" and python_version < \"4.0\"->datamodel-code-generator==0.26.1->label-studio-sdk==2.0.16->label-studio) (2.8.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\projects\\ml_learn\\end-to-end-projects\\ai_og\\.venv\\lib\\site-packages (from jsonschema>=2.6.0->drf-spectacular==0.28.0->label-studio) (2025.9.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\projects\\ml_learn\\end-to-end-projects\\ai_og\\.venv\\lib\\site-packages (from jsonschema>=2.6.0->drf-spectacular==0.28.0->label-studio) (0.37.0)\n",
      "Requirement already satisfied: rpds-py>=0.25.0 in c:\\projects\\ml_learn\\end-to-end-projects\\ai_og\\.venv\\lib\\site-packages (from jsonschema>=2.6.0->drf-spectacular==0.28.0->label-studio) (0.30.0)\n",
      "Requirement already satisfied: lxml_html_clean in c:\\projects\\ml_learn\\end-to-end-projects\\ai_og\\.venv\\lib\\site-packages (from lxml[html-clean]>=4.9.4->label-studio) (0.4.3)\n",
      "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in c:\\projects\\ml_learn\\end-to-end-projects\\ai_og\\.venv\\lib\\site-packages (from opentelemetry-api>=1.9.0->google-cloud-logging<4.0.0,>=3.10.0->label-studio) (8.7.1)\n",
      "Requirement already satisfied: zipp>=3.20 in c:\\projects\\ml_learn\\end-to-end-projects\\ai_og\\.venv\\lib\\site-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.9.0->google-cloud-logging<4.0.0,>=3.10.0->label-studio) (3.23.0)\n",
      "Requirement already satisfied: rich>=12.5.1 in c:\\projects\\ml_learn\\end-to-end-projects\\ai_og\\.venv\\lib\\site-packages (from pyboxen>=1.3.0->label-studio) (14.2.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\projects\\ml_learn\\end-to-end-projects\\ai_og\\.venv\\lib\\site-packages (from rich>=12.5.1->pyboxen>=1.3.0->label-studio) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\projects\\ml_learn\\end-to-end-projects\\ai_og\\.venv\\lib\\site-packages (from rich>=12.5.1->pyboxen>=1.3.0->label-studio) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\projects\\ml_learn\\end-to-end-projects\\ai_og\\.venv\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=12.5.1->pyboxen>=1.3.0->label-studio) (0.1.2)\n",
      "Requirement already satisfied: wrapt in c:\\projects\\ml_learn\\end-to-end-projects\\ai_og\\.venv\\lib\\site-packages (from smart-open>=6.3.0->smart-open[http]>=6.3.0->jsf<0.12.0,>=0.11.2->label-studio-sdk==2.0.16->label-studio) (2.0.1)\n",
      "Requirement already satisfied: requests-file>=1.4 in c:\\projects\\ml_learn\\end-to-end-projects\\ai_og\\.venv\\lib\\site-packages (from tldextract>=5.1.3->label-studio) (3.0.1)\n",
      "Requirement already satisfied: filelock>=3.0.8 in c:\\projects\\ml_learn\\end-to-end-projects\\ai_og\\.venv\\lib\\site-packages (from tldextract>=5.1.3->label-studio) (3.20.3)\n",
      "Requirement already satisfied: ua-parser>=0.10.0 in c:\\projects\\ml_learn\\end-to-end-projects\\ai_og\\.venv\\lib\\site-packages (from user-agents->django-user-agents==0.4.0->label-studio) (1.0.1)\n",
      "Requirement already satisfied: ua-parser-builtins in c:\\projects\\ml_learn\\end-to-end-projects\\ai_og\\.venv\\lib\\site-packages (from ua-parser>=0.10.0->user-agents->django-user-agents==0.4.0->label-studio) (202601)\n",
      "Downloading statsmodels-0.14.6-cp312-cp312-win_amd64.whl (9.5 MB)\n",
      "   ---------------------------------------- 0.0/9.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/9.5 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 0.8/9.5 MB 5.6 MB/s eta 0:00:02\n",
      "   ------ --------------------------------- 1.6/9.5 MB 3.5 MB/s eta 0:00:03\n",
      "   ------------- -------------------------- 3.1/9.5 MB 5.0 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 4.5/9.5 MB 5.3 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 6.6/9.5 MB 6.3 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 7.3/9.5 MB 5.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  9.4/9.5 MB 6.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 9.5/9.5 MB 6.3 MB/s  0:00:01\n",
      "Using cached seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
      "Using cached patsy-1.0.2-py2.py3-none-any.whl (233 kB)\n",
      "Installing collected packages: patsy, statsmodels, seaborn\n",
      "\n",
      "   ---------------------------------------- 0/3 [patsy]\n",
      "   ---------------------------------------- 0/3 [patsy]\n",
      "   ---------------------------------------- 0/3 [patsy]\n",
      "   ---------------------------------------- 0/3 [patsy]\n",
      "   ---------------------------------------- 0/3 [patsy]\n",
      "   ---------------------------------------- 0/3 [patsy]\n",
      "   ---------------------------------------- 0/3 [patsy]\n",
      "   ---------------------------------------- 0/3 [patsy]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   ------------- -------------------------- 1/3 [statsmodels]\n",
      "   -------------------------- ------------- 2/3 [seaborn]\n",
      "   -------------------------- ------------- 2/3 [seaborn]\n",
      "   -------------------------- ------------- 2/3 [seaborn]\n",
      "   -------------------------- ------------- 2/3 [seaborn]\n",
      "   -------------------------- ------------- 2/3 [seaborn]\n",
      "   -------------------------- ------------- 2/3 [seaborn]\n",
      "   -------------------------- ------------- 2/3 [seaborn]\n",
      "   -------------------------- ------------- 2/3 [seaborn]\n",
      "   -------------------------- ------------- 2/3 [seaborn]\n",
      "   -------------------------- ------------- 2/3 [seaborn]\n",
      "   -------------------------- ------------- 2/3 [seaborn]\n",
      "   -------------------------- ------------- 2/3 [seaborn]\n",
      "   -------------------------- ------------- 2/3 [seaborn]\n",
      "   -------------------------- ------------- 2/3 [seaborn]\n",
      "   -------------------------- ------------- 2/3 [seaborn]\n",
      "   -------------------------- ------------- 2/3 [seaborn]\n",
      "   ---------------------------------------- 3/3 [seaborn]\n",
      "\n",
      "Successfully installed patsy-1.0.2 seaborn-0.13.2 statsmodels-0.14.6\n"
     ]
    }
   ],
   "source": [
    "# Install required packages\n",
    "!pip install label-studio scikit-learn statsmodels pandas numpy matplotlib seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All imports successful!\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import cohen_kappa_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "\n",
    "print(\"All imports successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 2: Sample Data for Annotation\n",
    "\n",
    "### 2.1 Create Movie Review Dataset\n",
    "\n",
    "We'll create a set of movie reviews to annotate for sentiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 20 movie reviews for annotation\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0     Mind-blowing! Nolan does it again with this ma...\n",
       "1          So bad it's good. Hilarious unintentionally.\n",
       "2     Gripping from start to finish. Deserved every ...\n",
       "3                 What did I just watch? Truly bizarre.\n",
       "4             A timeless classic. Perfect in every way.\n",
       "5       Visually stunning but the story is predictable.\n",
       "6                Heath Ledger's Joker is unforgettable.\n",
       "7           Not my cup of tea but I can see the appeal.\n",
       "8     Made me cry. Beautiful exploration of love and...\n",
       "9                       Just... no. Avoid at all costs.\n",
       "10                   Tarantino's dialogue is unmatched.\n",
       "11    Ridiculous premise but entertaining in a weird...\n",
       "12          Hope is a good thing. Best movie ever made.\n",
       "13            Explosions. That's it. That's the review.\n",
       "14              Bittersweet ending that stays with you.\n",
       "15             Had potential but ended up being a mess.\n",
       "16              Miyazaki's imagination knows no bounds.\n",
       "17               An insult to the animated series fans.\n",
       "18                  Pixar at its finest. Remember me...\n",
       "19                 Okay but nothing special. Just okay.\n",
       "Name: review, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample movie reviews for annotation\n",
    "movie_reviews = [\n",
    "    {\"id\": 1, \"movie\": \"Inception\", \"Casts\": \"Leonardo DiCaprio, Joseph Gordon-Levitt, Ellen Page\", \"review\": \"Mind-blowing! Nolan does it again with this masterpiece.\"},\n",
    "    {\"id\": 2, \"movie\": \"The Room\", \"Casts\": \"Tommy Wiseau, Juliette Danielle, Greg Sestero\", \"review\": \"So bad it's good. Hilarious unintentionally.\"},\n",
    "    {\"id\": 3, \"movie\": \"Parasite\", \"Casts\": \"Song Kang-ho, Lee Sun-kyun, Choi Woo-shik\", \"review\": \"Gripping from start to finish. Deserved every Oscar.\"},\n",
    "    {\"id\": 4, \"movie\": \"Cats\", \"Casts\": \"James Corden, Judi Dench, Ian McKellen\", \"review\": \"What did I just watch? Truly bizarre.\"},\n",
    "    {\"id\": 5, \"movie\": \"The Godfather\", \"Casts\": \"Marlon Brando, Al Paccino, James Caan\", \"review\": \"A timeless classic. Perfect in every way.\"},\n",
    "    {\"id\": 6, \"movie\": \"Avatar\", \"Casts\": \"Sam Worthington, Zoe Saldana, Sigourney Weaver\", \"review\": \"Visually stunning but the story is predictable.\"},\n",
    "    {\"id\": 7, \"movie\": \"The Dark Knight\", \"Casts\": \"Christian Bale, Heath Ledger, Aaron Eckhart\", \"review\": \"Heath Ledger's Joker is unforgettable.\"},\n",
    "    {\"id\": 8, \"movie\": \"Twilight\",  \"Casts\": \"Kristen Stewart, Robert Pattinson, Taylor Lautner\", \"review\": \"Not my cup of tea but I can see the appeal.\"},\n",
    "    {\"id\": 9, \"movie\": \"Interstellar\", \"Casts\": \"Matthew McConaughey, Anne Hathaway, Jessica Chastain\", \"review\": \"Made me cry. Beautiful exploration of love and time.\"},\n",
    "    {\"id\": 10, \"movie\": \"Emoji Movie\", \"Casts\": \"T.J. Miller, James Corden, Anna Faris\", \"review\": \"Just... no. Avoid at all costs.\"},\n",
    "    {\"id\": 11, \"movie\": \"Pulp Fiction\", \"Casts\": \"John Travolta, Samuel L. Jackson, Uma Thurman\", \"review\": \"Tarantino's dialogue is unmatched.\"},\n",
    "    {\"id\": 12, \"movie\": \"Sharknado\",  \"Casts\": \"Ian Ziering, Tara Reid, John Heard\", \"review\": \"Ridiculous premise but entertaining in a weird way.\"},\n",
    "    {\"id\": 13, \"movie\": \"The Shawshank Redemption\", \"Casts\": \"Tim Robbins, Morgan Freeman, Bob Gunton\", \"review\": \"Hope is a good thing. Best movie ever made.\"},\n",
    "    {\"id\": 14, \"movie\": \"Transformers 5\", \"Casts\": \"Mark Wahlberg, Anthony Hopkins, Isabela Moner\", \"review\": \"Explosions. That's it. That's the review.\"},\n",
    "    {\"id\": 15, \"movie\": \"La La Land\", \"Casts\": \"Ryan Gosling, Emma Stone, John Legend\", \"review\": \"Bittersweet ending that stays with you.\"},\n",
    "    {\"id\": 16, \"movie\": \"Batman v Superman\",  \"Casts\": \"Ben Affleck, Henry Cavill, Amy Adams\", \"review\": \"Had potential but ended up being a mess.\"},\n",
    "    {\"id\": 17, \"movie\": \"Spirited Away\", \"Casts\": \"Rumi Hiiragi, Miyu Irino, Mari Natsuki\", \"review\": \"Miyazaki's imagination knows no bounds.\"},\n",
    "    {\"id\": 18, \"movie\": \"The Last Airbender\", \"Casts\": \"Noah Ringer, Nicola Peltz, Jackson Rathbone\", \"review\": \"An insult to the animated series fans.\"},\n",
    "    {\"id\": 19, \"movie\": \"Coco\", \"Casts\": \"Anthony Gonzalez, Gael Garca Bernal, Benjamin Bratt\", \"review\": \"Pixar at its finest. Remember me...\"},\n",
    "    {\"id\": 20, \"movie\": \"Justice League\", \"Casts\": \"Ben Affleck, Henry Cavill, Gal Gadot\", \"review\": \"Okay but nothing special. Just okay.\"},\n",
    "]\n",
    "\n",
    "df_reviews = pd.DataFrame(movie_reviews)\n",
    "print(f\"Created {len(df_reviews)} movie reviews for annotation\")\n",
    "df_reviews['review']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reviews['review'].to_csv('movie_reviews.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2.1 (Solved): Export Data for Label Studio\n",
    "\n",
    "Export the reviews in Label Studio's expected JSON format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported to movie_reviews_for_labeling.json\n",
      "\n",
      "Sample task:\n",
      "{\n",
      "  \"data\": {\n",
      "    \"id\": 1,\n",
      "    \"movie\": \"Inception\",\n",
      "    \"text\": \"Mind-blowing! Nolan does it again with this masterpiece.\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# SOLVED: Export for Label Studio\n",
    "def export_for_label_studio(df, text_column='review'):\n",
    "    \"\"\"\n",
    "    Export DataFrame to Label Studio JSON format.\n",
    "    \n",
    "    Label Studio expects a list of objects with a 'data' field.\n",
    "    \"\"\"\n",
    "    tasks = []\n",
    "    for _, row in df.iterrows():\n",
    "        task = {\n",
    "            \"data\": {\n",
    "                \"id\": int(row['id']),\n",
    "                \"movie\": row['movie'],\n",
    "                \"text\": row[text_column]\n",
    "            }\n",
    "        }\n",
    "        tasks.append(task)\n",
    "    return tasks\n",
    "\n",
    "tasks = export_for_label_studio(df_reviews)\n",
    "\n",
    "# Save to file\n",
    "with open('movie_reviews_for_labeling.json', 'w') as f:\n",
    "    json.dump(tasks, f, indent=2)\n",
    "\n",
    "print(\"Exported to movie_reviews_for_labeling.json\")\n",
    "print(\"\\nSample task:\")\n",
    "print(json.dumps(tasks[0], indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2.2: Add More Fields for Export\n",
    "\n",
    "Modify the export function to also include the movie title in the Label Studio interface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported to movie_reviews_for_labeling.json\n",
      "\n",
      "Sample task:\n",
      "{\n",
      "  \"data\": {\n",
      "    \"id\": 1,\n",
      "    \"title\": \"Inception\",\n",
      "    \"review\": \"Mind-blowing! Nolan does it again with this masterpiece.\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# TODO: Modify the export function to include movie title\n",
    "# The Label Studio interface should show both movie title and review\n",
    "\n",
    "# Your code here\n",
    "def export_for_label_studio(df, review_column='review', title_column='movie'):\n",
    "    tasks = []\n",
    "    for _, row in df.iterrows():\n",
    "        task = {\n",
    "            \"data\": {\n",
    "                \"id\": int(row['id']),\n",
    "                \"title\": row[title_column],\n",
    "                \"review\": row[review_column]\n",
    "            }\n",
    "        }\n",
    "        tasks.append(task)\n",
    "    return tasks\n",
    "\n",
    "tasks = export_for_label_studio(df_reviews)\n",
    "\n",
    "# Save to file\n",
    "with open('movie_reviews_for_labeling.json', 'w') as f:\n",
    "    json.dump(tasks, f, indent=2)\n",
    "\n",
    "print(\"Exported to movie_reviews_for_labeling.json\")\n",
    "print(\"\\nSample task:\")\n",
    "print(json.dumps(tasks[0], indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 3: Label Studio Configuration\n",
    "\n",
    "### 3.1 Understanding Label Studio XML Configs\n",
    "\n",
    "Label Studio uses XML to define annotation interfaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment Classification Config:\n",
      "\n",
      "<View>\n",
      "  <Header value=\"Movie Review Sentiment Analysis\"/>\n",
      "  <Text name=\"text\" value=\"$text\"/>\n",
      "  <Choices name=\"sentiment\" toName=\"text\" choice=\"single\">\n",
      "    <Choice value=\"Positive\" hotkey=\"1\"/>\n",
      "    <Choice value=\"Negative\" hotkey=\"2\"/>\n",
      "    <Choice value=\"Neutral\" hotkey=\"3\"/>\n",
      "    <Choice value=\"Mixed\" hotkey=\"4\"/>\n",
      "  </Choices>\n",
      "</View>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Text Classification Config for Sentiment Analysis\n",
    "sentiment_config = '''\n",
    "<View>\n",
    "  <Header value=\"Movie Review Sentiment Analysis\"/>\n",
    "  <Text name=\"text\" value=\"$text\"/>\n",
    "  <Choices name=\"sentiment\" toName=\"text\" choice=\"single\">\n",
    "    <Choice value=\"Positive\" hotkey=\"1\"/>\n",
    "    <Choice value=\"Negative\" hotkey=\"2\"/>\n",
    "    <Choice value=\"Neutral\" hotkey=\"3\"/>\n",
    "    <Choice value=\"Mixed\" hotkey=\"4\"/>\n",
    "  </Choices>\n",
    "</View>\n",
    "'''\n",
    "\n",
    "print(\"Sentiment Classification Config:\")\n",
    "print(sentiment_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3.1 (Solved): Create NER Config\n",
    "\n",
    "Create a Label Studio config for Named Entity Recognition on movie reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NER Config for Movie Reviews:\n",
      "\n",
      "<View>\n",
      "  <Header value=\"Movie Entity Annotation\"/>\n",
      "  <Labels name=\"ner\" toName=\"text\">\n",
      "    <Label value=\"MOVIE_TITLE\" background=\"#FF0000\"/>\n",
      "    <Label value=\"ACTOR\" background=\"#00FF00\"/>\n",
      "    <Label value=\"DIRECTOR\" background=\"#0000FF\"/>\n",
      "    <Label value=\"CHARACTER\" background=\"#FFA500\"/>\n",
      "    <Label value=\"AWARD\" background=\"#800080\"/>\n",
      "  </Labels>\n",
      "  <Text name=\"text\" value=\"$text\"/>\n",
      "</View>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SOLVED: NER Config for Movie Reviews\n",
    "ner_config = '''\n",
    "<View>\n",
    "  <Header value=\"Movie Entity Annotation\"/>\n",
    "  <Labels name=\"ner\" toName=\"text\">\n",
    "    <Label value=\"MOVIE_TITLE\" background=\"#FF0000\"/>\n",
    "    <Label value=\"ACTOR\" background=\"#00FF00\"/>\n",
    "    <Label value=\"DIRECTOR\" background=\"#0000FF\"/>\n",
    "    <Label value=\"CHARACTER\" background=\"#FFA500\"/>\n",
    "    <Label value=\"AWARD\" background=\"#800080\"/>\n",
    "  </Labels>\n",
    "  <Text name=\"text\" value=\"$text\"/>\n",
    "</View>\n",
    "'''\n",
    "\n",
    "print(\"NER Config for Movie Reviews:\")\n",
    "print(ner_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3.2: Create Multi-Label Classification Config\n",
    "\n",
    "Create a config that allows multiple labels per review (e.g., \"Funny\", \"Emotional\", \"Action-packed\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create multi-label classification config\n",
    "# Hint: Use choice=\"multiple\" instead of choice=\"single\"\n",
    "\n",
    "# Your config here\n",
    "multi_label_config = '''\n",
    "<View>\n",
    "  <Header value=\"Multi Label Classification\"/>\n",
    "  <Text name=\"text\" value=\"$text\"/>\n",
    "  <Choices name=\"multi-label\" toName=\"text\" choice=\"multiple\">\n",
    "    <Choice value=\"Funny\" hotkey=\"1\" />\n",
    "    <Choice value=\"Emotional\" hotkey=\"2\" />\n",
    "    <Choice value=\"Action-packed\" hotkey=\"3\" />\n",
    "    <Choice value=\"CHARACTER\" hotkey=\"4\" />\n",
    "    <Choice value=\"AWARD\" hotkey=\"5\" />\n",
    "  </Choices>\n",
    "</View>\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3.3: Create Image Classification Config\n",
    "\n",
    "Create a config for classifying movie poster genres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create image classification config for movie poster genre classification\n",
    "# Include genres: Action, Comedy, Drama, Horror, Sci-Fi, Romance\n",
    "\n",
    "# Your config here\n",
    "classification_config = '''\n",
    "<View>\n",
    "    <Header value=\"Movie Poster Genre Classification\"/>\n",
    "    <Image name=\"image\" value=\"$image\" />\n",
    "    <Choices name=\"classification\" toName=\"text\" choice=\"multiple\">\n",
    "        <Choice value=\"Action\" hotkey=\"1\" />\n",
    "        <Choice value=\"Comedy\" hotkey=\"2\" />\n",
    "        <Choice value=\"Drama\" hotkey=\"3\" />\n",
    "        <Choice value=\"Horror\" hotkey=\"4\" />\n",
    "        <Choice value=\"Sci-Fi\" hotkey=\"5\" />\n",
    "        <Choice value=\"Romance\" hotkey=\"6\" />\n",
    "    </Choices>\n",
    "</View>\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 4: Annotation Guidelines\n",
    "\n",
    "### 4.1 Writing Clear Guidelines\n",
    "\n",
    "Good annotation guidelines are crucial for consistent labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# Movie Review Sentiment Annotation Guidelines\n",
      "\n",
      "## Task Overview\n",
      "Classify movie reviews into sentiment categories based on the reviewer's opinion of the movie.\n",
      "\n",
      "## Label Definitions\n",
      "\n",
      "### POSITIVE\n",
      "The reviewer clearly enjoyed the movie and recommends it.\n",
      "\n",
      "**Examples:**\n",
      "- \"Mind-blowing! Nolan does it again with this masterpiece.\"\n",
      "- \"Best movie I've seen this year. A must-watch!\"\n",
      "- \"Perfect in every way. 10/10.\"\n",
      "\n",
      "### NEGATIVE\n",
      "The reviewer clearly did not enjoy the movie and does not recommend it.\n",
      "\n",
      "**Examples:**\n",
      "- \"Avoid at all costs. Complete waste of time.\"\n",
      "- \"An insult to the animated series fans.\"\n",
      "- \"Just... no. Terrible.\"\n",
      "\n",
      "### NEUTRAL\n",
      "The reviewer has no strong opinion either way, or the review is purely factual.\n",
      "\n",
      "**Examples:**\n",
      "- \"It's okay. Nothing special.\"\n",
      "- \"The movie is 2 hours long and features action scenes.\"\n",
      "- \"Just okay.\"\n",
      "\n",
      "### MIXED\n",
      "The review contains both positive and negative aspects.\n",
      "\n",
      "**Examples:**\n",
      "- \"Visually stunning but the story is predictable.\"\n",
      "- \"Great acting but poor direction.\"\n",
      "- \"Had potential but ended up being a mess.\"\n",
      "\n",
      "## Edge Cases\n",
      "\n",
      "### Sarcasm\n",
      "If sarcasm is detected, label based on the ACTUAL meaning, not the literal words.\n",
      "- \"Oh great, another superhero movie. Just what we needed.\"  NEGATIVE\n",
      "\n",
      "### \"So bad it's good\"\n",
      "Movies praised ironically should be labeled MIXED (enjoyment exists but film quality is poor).\n",
      "- \"So bad it's good. Hilarious unintentionally.\"  MIXED\n",
      "\n",
      "### Qualified Praise/Criticism\n",
      "If the reviewer has reservations, use MIXED.\n",
      "- \"Not my cup of tea but I can see the appeal.\"  NEUTRAL (not recommending but not criticizing)\n",
      "\n",
      "## When in Doubt\n",
      "1. Re-read the review\n",
      "2. Ask: \"Would the reviewer recommend this movie?\"\n",
      "3. If still unclear, use NEUTRAL\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Example annotation guidelines\n",
    "annotation_guidelines = \"\"\"\n",
    "# Movie Review Sentiment Annotation Guidelines\n",
    "\n",
    "## Task Overview\n",
    "Classify movie reviews into sentiment categories based on the reviewer's opinion of the movie.\n",
    "\n",
    "## Label Definitions\n",
    "\n",
    "### POSITIVE\n",
    "The reviewer clearly enjoyed the movie and recommends it.\n",
    "\n",
    "**Examples:**\n",
    "- \"Mind-blowing! Nolan does it again with this masterpiece.\"\n",
    "- \"Best movie I've seen this year. A must-watch!\"\n",
    "- \"Perfect in every way. 10/10.\"\n",
    "\n",
    "### NEGATIVE\n",
    "The reviewer clearly did not enjoy the movie and does not recommend it.\n",
    "\n",
    "**Examples:**\n",
    "- \"Avoid at all costs. Complete waste of time.\"\n",
    "- \"An insult to the animated series fans.\"\n",
    "- \"Just... no. Terrible.\"\n",
    "\n",
    "### NEUTRAL\n",
    "The reviewer has no strong opinion either way, or the review is purely factual.\n",
    "\n",
    "**Examples:**\n",
    "- \"It's okay. Nothing special.\"\n",
    "- \"The movie is 2 hours long and features action scenes.\"\n",
    "- \"Just okay.\"\n",
    "\n",
    "### MIXED\n",
    "The review contains both positive and negative aspects.\n",
    "\n",
    "**Examples:**\n",
    "- \"Visually stunning but the story is predictable.\"\n",
    "- \"Great acting but poor direction.\"\n",
    "- \"Had potential but ended up being a mess.\"\n",
    "\n",
    "## Edge Cases\n",
    "\n",
    "### Sarcasm\n",
    "If sarcasm is detected, label based on the ACTUAL meaning, not the literal words.\n",
    "- \"Oh great, another superhero movie. Just what we needed.\"  NEGATIVE\n",
    "\n",
    "### \"So bad it's good\"\n",
    "Movies praised ironically should be labeled MIXED (enjoyment exists but film quality is poor).\n",
    "- \"So bad it's good. Hilarious unintentionally.\"  MIXED\n",
    "\n",
    "### Qualified Praise/Criticism\n",
    "If the reviewer has reservations, use MIXED.\n",
    "- \"Not my cup of tea but I can see the appeal.\"  NEUTRAL (not recommending but not criticizing)\n",
    "\n",
    "## When in Doubt\n",
    "1. Re-read the review\n",
    "2. Ask: \"Would the reviewer recommend this movie?\"\n",
    "3. If still unclear, use NEUTRAL\n",
    "\"\"\"\n",
    "\n",
    "print(annotation_guidelines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4.1: Add Edge Cases to Guidelines\n",
    "\n",
    "What other edge cases should be added to these guidelines?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Write 3 additional edge cases that should be covered in the guidelines\n",
    "# Consider: emojis, ratings, comparisons to other movies, etc.\n",
    "\n",
    "additional_edge_cases = \"\"\"\n",
    "### Edge Case 1: Emojis in Reviews\n",
    "If emojis are used, interpret their sentiment in context with the text.\n",
    "\n",
    "### Edge Case 2: Ratings in Reviews\n",
    "If numerical ratings are mentioned, consider them as part of the overall sentiment.\n",
    "\n",
    "### Edge Case 3: Comparisons to Other Movies\n",
    "If the review compares the movie to others, focus on the sentiment towards the movie being reviewed.\n",
    "\"\"\"\n",
    "\n",
    "# Your edge cases here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 5: Simulating Annotations\n",
    "\n",
    "### 5.1 Creating Simulated Annotator Data\n",
    "\n",
    "For this lab, we'll simulate multiple annotators to practice IAA calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulated Annotations:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>annotator_1</th>\n",
       "      <th>annotator_2</th>\n",
       "      <th>annotator_3</th>\n",
       "      <th>ground_truth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Mixed</td>\n",
       "      <td>Mixed</td>\n",
       "      <td>Mixed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Mixed</td>\n",
       "      <td>Mixed</td>\n",
       "      <td>Mixed</td>\n",
       "      <td>Mixed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Mixed</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>Mixed</td>\n",
       "      <td>Mixed</td>\n",
       "      <td>Mixed</td>\n",
       "      <td>Mixed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>Mixed</td>\n",
       "      <td>Mixed</td>\n",
       "      <td>Mixed</td>\n",
       "      <td>Mixed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Mixed</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    review_id annotator_1 annotator_2 annotator_3 ground_truth\n",
       "0           1    Positive    Positive     Neutral     Positive\n",
       "1           2     Neutral       Mixed       Mixed        Mixed\n",
       "2           3    Positive    Positive    Positive     Positive\n",
       "3           4    Negative    Negative    Negative     Negative\n",
       "4           5    Positive    Positive    Positive     Positive\n",
       "5           6       Mixed       Mixed       Mixed        Mixed\n",
       "6           7    Positive    Positive     Neutral     Positive\n",
       "7           8     Neutral     Neutral     Neutral      Neutral\n",
       "8           9    Positive    Positive    Positive     Positive\n",
       "9          10    Negative    Negative       Mixed     Negative\n",
       "10         11    Positive    Positive     Neutral     Positive\n",
       "11         12       Mixed       Mixed       Mixed        Mixed\n",
       "12         13     Neutral     Neutral    Positive     Positive\n",
       "13         14    Negative    Positive    Negative     Negative\n",
       "14         15       Mixed       Mixed       Mixed        Mixed\n",
       "15         16    Negative    Negative    Negative     Negative\n",
       "16         17    Positive    Positive     Neutral     Positive\n",
       "17         18    Negative    Negative    Positive     Negative\n",
       "18         19    Positive    Positive    Positive     Positive\n",
       "19         20     Neutral       Mixed    Positive      Neutral"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Simulated annotations from two annotators\n",
    "np.random.seed(42)\n",
    "\n",
    "# Ground truth labels (for simulation)\n",
    "ground_truth = ['Positive', 'Mixed', 'Positive', 'Negative', 'Positive',\n",
    "                'Mixed', 'Positive', 'Neutral', 'Positive', 'Negative',\n",
    "                'Positive', 'Mixed', 'Positive', 'Negative', 'Mixed',\n",
    "                'Negative', 'Positive', 'Negative', 'Positive', 'Neutral']\n",
    "\n",
    "# Annotator 1: 90% accuracy\n",
    "def simulate_annotator(true_labels, accuracy=0.9):\n",
    "    labels = ['Positive', 'Negative', 'Neutral', 'Mixed']\n",
    "    annotations = []\n",
    "    for true_label in true_labels:\n",
    "        if np.random.random() < accuracy:\n",
    "            annotations.append(true_label)\n",
    "        else:\n",
    "            # Random different label\n",
    "            other_labels = [l for l in labels if l != true_label]\n",
    "            annotations.append(np.random.choice(other_labels))\n",
    "    return annotations\n",
    "\n",
    "annotator1 = simulate_annotator(ground_truth, accuracy=0.85)\n",
    "annotator2 = simulate_annotator(ground_truth, accuracy=0.80)\n",
    "annotator3 = simulate_annotator(ground_truth, accuracy=0.75)\n",
    "\n",
    "# Create DataFrame\n",
    "annotations_df = pd.DataFrame({\n",
    "    'review_id': range(1, 21),\n",
    "    'annotator_1': annotator1,\n",
    "    'annotator_2': annotator2,\n",
    "    'annotator_3': annotator3,\n",
    "    'ground_truth': ground_truth\n",
    "})\n",
    "\n",
    "print(\"Simulated Annotations:\")\n",
    "annotations_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5.1 (Solved): Calculate Percent Agreement\n",
    "\n",
    "Calculate the simple percent agreement between annotators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent Agreement (Annotator 1 vs 2): 85.00%\n",
      "Percent Agreement (Annotator 1 vs 3): 55.00%\n",
      "Percent Agreement (Annotator 2 vs 3): 55.00%\n",
      "\n",
      "Average Pairwise Agreement: 65.00%\n"
     ]
    }
   ],
   "source": [
    "# SOLVED: Calculate percent agreement\n",
    "def percent_agreement(labels1, labels2):\n",
    "    \"\"\"\n",
    "    Calculate the percentage of items where two annotators agree.\n",
    "    \"\"\"\n",
    "    agreements = sum(l1 == l2 for l1, l2 in zip(labels1, labels2))\n",
    "    return agreements / len(labels1)\n",
    "\n",
    "# Calculate pairwise agreements\n",
    "pa_1_2 = percent_agreement(annotator1, annotator2)\n",
    "pa_1_3 = percent_agreement(annotator1, annotator3)\n",
    "pa_2_3 = percent_agreement(annotator2, annotator3)\n",
    "\n",
    "print(f\"Percent Agreement (Annotator 1 vs 2): {pa_1_2:.2%}\")\n",
    "print(f\"Percent Agreement (Annotator 1 vs 3): {pa_1_3:.2%}\")\n",
    "print(f\"Percent Agreement (Annotator 2 vs 3): {pa_2_3:.2%}\")\n",
    "print(f\"\\nAverage Pairwise Agreement: {(pa_1_2 + pa_1_3 + pa_2_3) / 3:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5.2: Why is Percent Agreement Not Enough?\n",
    "\n",
    "Explain the limitation of percent agreement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Write your explanation here\n",
    "# Hint: Consider what happens with random guessing in a binary classification task\n",
    "\n",
    "explanation = \"\"\"\n",
    "In binary classification task, There 50% probability that both agree by change because each lable has 50% probablity to be selected.\n",
    "As the number of classes increases, the probability of random agreement decreases. So Percent Agreement is Not Enough to measure inter-annotator reliability.\n",
    "We need some other metric which tells us \"How much better than random we are?\"\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 6: Cohen's Kappa\n",
    "\n",
    "### 6.1 Understanding Cohen's Kappa\n",
    "\n",
    "Cohen's Kappa accounts for agreement by chance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cohen's Kappa Formula:\n",
      "\n",
      "           P_observed - P_expected\n",
      "kappa = \n",
      "            1 - P_expected\n",
      "\n",
      "Where:\n",
      "- P_observed = Actual agreement rate\n",
      "- P_expected = Expected agreement by chance\n",
      "\n",
      "Interpretation:\n",
      "- kappa < 0.00: Poor (worse than chance)\n",
      "- 0.00 - 0.20: Slight\n",
      "- 0.21 - 0.40: Fair\n",
      "- 0.41 - 0.60: Moderate\n",
      "- 0.61 - 0.80: Substantial\n",
      "- 0.81 - 1.00: Almost Perfect\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cohen's Kappa formula explanation\n",
    "print(\"\"\"\n",
    "Cohen's Kappa Formula:\n",
    "\n",
    "           P_observed - P_expected\n",
    "kappa = \n",
    "            1 - P_expected\n",
    "\n",
    "Where:\n",
    "- P_observed = Actual agreement rate\n",
    "- P_expected = Expected agreement by chance\n",
    "\n",
    "Interpretation:\n",
    "- kappa < 0.00: Poor (worse than chance)\n",
    "- 0.00 - 0.20: Slight\n",
    "- 0.21 - 0.40: Fair\n",
    "- 0.41 - 0.60: Moderate\n",
    "- 0.61 - 0.80: Substantial\n",
    "- 0.81 - 1.00: Almost Perfect\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6.1 (Solved): Calculate Cohen's Kappa Step-by-Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annotator 1 vs Annotator 2:\n",
      "Observed Agreement (P_o): 0.8500\n",
      "Expected Agreement (P_e): 0.2875\n",
      "Cohen's Kappa: 0.7895\n",
      "\n",
      "==================================================\n",
      "\n",
      "Sklearn Cohen's Kappa: 0.7895\n"
     ]
    }
   ],
   "source": [
    "# SOLVED: Manual Cohen's Kappa calculation\n",
    "def cohens_kappa_manual(labels1, labels2):\n",
    "    \"\"\"\n",
    "    Calculate Cohen's Kappa step by step.\n",
    "    \"\"\"\n",
    "    # Step 1: Create confusion matrix\n",
    "    unique_labels = sorted(set(labels1) | set(labels2))\n",
    "    n = len(labels1)\n",
    "    \n",
    "    # Count agreements and marginals\n",
    "    confusion = {}\n",
    "    for l1 in unique_labels:\n",
    "        confusion[l1] = {l2: 0 for l2 in unique_labels}\n",
    "    \n",
    "    for l1, l2 in zip(labels1, labels2):\n",
    "        confusion[l1][l2] += 1\n",
    "    \n",
    "    # Step 2: Calculate observed agreement\n",
    "    p_observed = sum(confusion[l][l] for l in unique_labels) / n\n",
    "    \n",
    "    # Step 3: Calculate expected agreement\n",
    "    marginals_1 = {l: sum(1 for x in labels1 if x == l) / n for l in unique_labels}\n",
    "    marginals_2 = {l: sum(1 for x in labels2 if x == l) / n for l in unique_labels}\n",
    "    \n",
    "    p_expected = sum(marginals_1[l] * marginals_2[l] for l in unique_labels)\n",
    "    \n",
    "    # Step 4: Calculate kappa\n",
    "    kappa = (p_observed - p_expected) / (1 - p_expected)\n",
    "    \n",
    "    print(f\"Observed Agreement (P_o): {p_observed:.4f}\")\n",
    "    print(f\"Expected Agreement (P_e): {p_expected:.4f}\")\n",
    "    print(f\"Cohen's Kappa: {kappa:.4f}\")\n",
    "    \n",
    "    return kappa\n",
    "\n",
    "print(\"Annotator 1 vs Annotator 2:\")\n",
    "kappa_1_2 = cohens_kappa_manual(annotator1, annotator2)\n",
    "\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# Verify with sklearn\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "sklearn_kappa = cohen_kappa_score(annotator1, annotator2)\n",
    "print(f\"Sklearn Cohen's Kappa: {sklearn_kappa:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6.2: Calculate All Pairwise Kappas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kappa (Annotator 1 vs 2): 78.95%\n",
      "Kappa (Annotator 1 vs 3): 38.78%\n",
      "Kappa (Annotator 2 vs 3): 37.93%\n"
     ]
    }
   ],
   "source": [
    "# TODO: Calculate Cohen's Kappa for all pairs of annotators\n",
    "# Use sklearn's cohen_kappa_score function\n",
    "\n",
    "# Your code here\n",
    "kappa_12 = cohen_kappa_score(annotator1, annotator2)\n",
    "kappa_13 = cohen_kappa_score(annotator1, annotator3)\n",
    "kappa_23 = cohen_kappa_score(annotator2, annotator3)\n",
    "\n",
    "print(f\"Kappa (Annotator 1 vs 2): {kappa_12:.2%}\")\n",
    "print(f\"Kappa (Annotator 1 vs 3): {kappa_13:.2%}\")\n",
    "print(f\"Kappa (Annotator 2 vs 3): {kappa_23:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6.3: Visualize Agreement with Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TODO: Create a confusion matrix heatmap for Annotator 1 vs Annotator 2\n",
    "# Hint: Use sklearn's confusion_matrix and seaborn's heatmap\n",
    "\n",
    "# Your code here\n",
    "confusion_12 = confusion_matrix(annotator1, annotator2)\n",
    "sns.heatmap(confusion_12, cmap='Blues')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 7: Fleiss' Kappa for Multiple Annotators\n",
    "\n",
    "### 7.1 Understanding Fleiss' Kappa\n",
    "\n",
    "When you have more than 2 annotators, use Fleiss' Kappa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data matrix shape: (20, 4)\n",
      "\n",
      "First 5 rows (counts per category):\n",
      "   Positive  Negative  Neutral  Mixed\n",
      "0         2         0        1      0\n",
      "1         0         0        1      2\n",
      "2         3         0        0      0\n",
      "3         0         3        0      0\n",
      "4         3         0        0      0\n"
     ]
    }
   ],
   "source": [
    "# Fleiss' Kappa using statsmodels\n",
    "from statsmodels.stats.inter_rater import fleiss_kappa, aggregate_raters\n",
    "\n",
    "# Prepare data for Fleiss' Kappa\n",
    "# Format: (n_items, n_categories) matrix with counts\n",
    "\n",
    "labels = ['Positive', 'Negative', 'Neutral', 'Mixed']\n",
    "n_items = len(annotator1)\n",
    "\n",
    "# Create matrix\n",
    "data_matrix = []\n",
    "for i in range(n_items):\n",
    "    row = [0, 0, 0, 0]  # Counts for each category\n",
    "    for ann in [annotator1[i], annotator2[i], annotator3[i]]:\n",
    "        row[labels.index(ann)] += 1\n",
    "    data_matrix.append(row)\n",
    "\n",
    "data_matrix = np.array(data_matrix)\n",
    "print(\"Data matrix shape:\", data_matrix.shape)\n",
    "print(\"\\nFirst 5 rows (counts per category):\")\n",
    "print(pd.DataFrame(data_matrix[:5], columns=labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 7.1 (Solved): Calculate Fleiss' Kappa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fleiss' Kappa (3 annotators): 0.5135\n",
      "Interpretation: Moderate agreement\n"
     ]
    }
   ],
   "source": [
    "# SOLVED: Calculate Fleiss' Kappa\n",
    "fk = fleiss_kappa(data_matrix)\n",
    "print(f\"Fleiss' Kappa (3 annotators): {fk:.4f}\")\n",
    "\n",
    "# Interpret\n",
    "if fk < 0:\n",
    "    print(\"Interpretation: Poor (worse than chance)\")\n",
    "elif fk < 0.20:\n",
    "    print(\"Interpretation: Slight agreement\")\n",
    "elif fk < 0.40:\n",
    "    print(\"Interpretation: Fair agreement\")\n",
    "elif fk < 0.60:\n",
    "    print(\"Interpretation: Moderate agreement\")\n",
    "elif fk < 0.80:\n",
    "    print(\"Interpretation: Substantial agreement\")\n",
    "else:\n",
    "    print(\"Interpretation: Almost perfect agreement\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 7.2: How Would You Improve Agreement?\n",
    "\n",
    "Based on the Fleiss' Kappa score, what actions would you take?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Write 3 specific actions to improve annotator agreement\n",
    "\n",
    "improvement_actions = \"\"\"\n",
    "1. Make a strict annotation guideline to improve the agreement between the annotators.\n",
    "\n",
    "2. Conduct training for annotators to calibrate rounds until k > 0.8 is achieved. Train them with small batch of examples \n",
    "\n",
    "3. Inject a small portion (10%) of pre-labeled, trusted items into the stream. This keep quality high during the production.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 8: IoU for Spatial Annotations\n",
    "\n",
    "### 8.1 Intersection over Union (IoU)\n",
    "\n",
    "For bounding boxes and segmentation, we use IoU to measure agreement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Intersection over Union (IoU):\n",
      "\n",
      "           Area of Overlap\n",
      "IoU = \n",
      "         Area of Union\n",
      "\n",
      "      \n",
      "          \n",
      "          ////////       \n",
      "          //Ovrlp/       \n",
      "             \n",
      "                           \n",
      "           \n",
      "\n",
      "IoU = Overlap / (Box1 + Box2 - Overlap)\n",
      "\n",
      "Thresholds:\n",
      "- IoU > 0.5: Match (standard)\n",
      "- IoU > 0.7: Good match\n",
      "- IoU > 0.9: Excellent match\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# IoU explanation\n",
    "print(\"\"\"\n",
    "Intersection over Union (IoU):\n",
    "\n",
    "           Area of Overlap\n",
    "IoU = \n",
    "         Area of Union\n",
    "\n",
    "      \n",
    "          \n",
    "          ////////       \n",
    "          //Ovrlp/       \n",
    "             \n",
    "                           \n",
    "           \n",
    "\n",
    "IoU = Overlap / (Box1 + Box2 - Overlap)\n",
    "\n",
    "Thresholds:\n",
    "- IoU > 0.5: Match (standard)\n",
    "- IoU > 0.7: Good match\n",
    "- IoU > 0.9: Excellent match\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 8.1 (Solved): Implement IoU Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IoU(box1, box2): 0.1429\n",
      "IoU(box1, box3): 0.0000\n",
      "IoU(box1, box4): 0.2500\n"
     ]
    }
   ],
   "source": [
    "# SOLVED: IoU Implementation\n",
    "def calculate_iou(box1, box2):\n",
    "    \"\"\"\n",
    "    Calculate IoU between two bounding boxes.\n",
    "    \n",
    "    Args:\n",
    "        box1, box2: Lists of [x1, y1, x2, y2] coordinates\n",
    "    \n",
    "    Returns:\n",
    "        IoU value (0 to 1)\n",
    "    \"\"\"\n",
    "    # Calculate intersection coordinates\n",
    "    x1 = max(box1[0], box2[0])\n",
    "    y1 = max(box1[1], box2[1])\n",
    "    x2 = min(box1[2], box2[2])\n",
    "    y2 = min(box1[3], box2[3])\n",
    "    \n",
    "    # Check for no overlap\n",
    "    if x2 < x1 or y2 < y1:\n",
    "        return 0.0\n",
    "    \n",
    "    # Calculate areas\n",
    "    intersection = (x2 - x1) * (y2 - y1)\n",
    "    \n",
    "    area1 = (box1[2] - box1[0]) * (box1[3] - box1[1])\n",
    "    area2 = (box2[2] - box2[0]) * (box2[3] - box2[1])\n",
    "    \n",
    "    union = area1 + area2 - intersection\n",
    "    \n",
    "    return intersection / union\n",
    "\n",
    "# Test cases\n",
    "box1 = [0, 0, 100, 100]  # 100x100 box at origin\n",
    "box2 = [50, 50, 150, 150]  # 100x100 box shifted by 50\n",
    "box3 = [200, 200, 300, 300]  # No overlap\n",
    "box4 = [25, 25, 75, 75]  # Contained within box1\n",
    "\n",
    "print(f\"IoU(box1, box2): {calculate_iou(box1, box2):.4f}\")  # Partial overlap\n",
    "print(f\"IoU(box1, box3): {calculate_iou(box1, box3):.4f}\")  # No overlap\n",
    "print(f\"IoU(box1, box4): {calculate_iou(box1, box4):.4f}\")  # One inside other"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 8.2: Calculate IoU for Movie Poster Annotations\n",
    "\n",
    "Two annotators drew bounding boxes around movie titles on posters. Calculate their IoU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IoU for Inception is 0.82\n",
      "IoU for The Matrix is 0.79\n",
      "IoU for Avatar is 0.86\n",
      "IoU for Titanic is 0.66\n",
      "Mean IoU 0.78\n"
     ]
    }
   ],
   "source": [
    "# Bounding box annotations from two annotators\n",
    "poster_annotations = [\n",
    "    {\"poster\": \"Inception\", \"ann1\": [100, 50, 300, 100], \"ann2\": [95, 55, 305, 98]},\n",
    "    {\"poster\": \"The Matrix\", \"ann1\": [50, 100, 250, 180], \"ann2\": [60, 105, 240, 175]},\n",
    "    {\"poster\": \"Avatar\", \"ann1\": [120, 80, 280, 150], \"ann2\": [125, 78, 275, 155]},\n",
    "    {\"poster\": \"Titanic\", \"ann1\": [80, 60, 320, 120], \"ann2\": [100, 70, 310, 115]},\n",
    "]\n",
    "\n",
    "# TODO: Calculate IoU for each poster and compute the mean IoU\n",
    "\n",
    "# Your code here\n",
    "IoU = {}\n",
    "for poster in poster_annotations:\n",
    "    IoU[poster['poster']] = calculate_iou(poster['ann1'], poster['ann2'])\n",
    "    \n",
    "for poster, iou in IoU.items():\n",
    "    print(f\"IoU for {poster} is {iou:.2f}\")\n",
    "    \n",
    "print(f\"Mean IoU {sum(IoU.values())/len(IoU.values()):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 8.3: Visualize Bounding Box Overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      8\u001b[39m box1 = [\u001b[32m60\u001b[39m, \u001b[32m60\u001b[39m, \u001b[32m320\u001b[39m, \u001b[32m120\u001b[39m]\n\u001b[32m      9\u001b[39m box2 = [\u001b[32m100\u001b[39m, \u001b[32m70\u001b[39m, \u001b[32m310\u001b[39m, \u001b[32m115\u001b[39m]\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m fig, ax = \u001b[43mplt\u001b[49m.subplots()\n\u001b[32m     13\u001b[39m rect1 = patches.Rectangle((box1[\u001b[32m0\u001b[39m], box1[\u001b[32m1\u001b[39m]), box1[\u001b[32m2\u001b[39m], box1[\u001b[32m3\u001b[39m], linewidth=\u001b[32m1\u001b[39m, facecolor=\u001b[33m'\u001b[39m\u001b[33mblue\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     14\u001b[39m rect2 = patches.Rectangle((box2[\u001b[32m0\u001b[39m], box2[\u001b[32m1\u001b[39m]), box2[\u001b[32m2\u001b[39m], box2[\u001b[32m3\u001b[39m], linewidth=\u001b[32m1\u001b[39m, facecolor=\u001b[33m'\u001b[39m\u001b[33mred\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "# TODO: Create a visualization showing two overlapping bounding boxes\n",
    "# Use matplotlib to draw rectangles\n",
    "# Hint: matplotlib.patches.Rectangle\n",
    "\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "# Your code here\n",
    "box1 = [60, 60, 320, 120]\n",
    "box2 = [100, 70, 310, 115]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "rect1 = patches.Rectangle((box1[0], box1[1]), box1[2], box1[3], linewidth=1, facecolor='blue')\n",
    "rect2 = patches.Rectangle((box2[0], box2[1]), box2[2], box2[3], linewidth=1, facecolor='red')\n",
    "\n",
    "ax.add_patch(rect1)\n",
    "ax.add_patch(rect2)\n",
    "\n",
    "ax.set_xlim(0, 500)\n",
    "ax.set_ylim(0, 200)\n",
    "ax.set_aspect('equal')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 9: Majority Voting and Adjudication\n",
    "\n",
    "### 9.1 Resolving Disagreements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels with Majority Vote:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>annotator_1</th>\n",
       "      <th>annotator_2</th>\n",
       "      <th>annotator_3</th>\n",
       "      <th>majority_vote</th>\n",
       "      <th>ground_truth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Mixed</td>\n",
       "      <td>Mixed</td>\n",
       "      <td>Mixed</td>\n",
       "      <td>Mixed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Mixed</td>\n",
       "      <td>Mixed</td>\n",
       "      <td>Mixed</td>\n",
       "      <td>Mixed</td>\n",
       "      <td>Mixed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Mixed</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   review_id annotator_1 annotator_2 annotator_3 majority_vote ground_truth\n",
       "0          1    Positive    Positive     Neutral      Positive     Positive\n",
       "1          2     Neutral       Mixed       Mixed         Mixed        Mixed\n",
       "2          3    Positive    Positive    Positive      Positive     Positive\n",
       "3          4    Negative    Negative    Negative      Negative     Negative\n",
       "4          5    Positive    Positive    Positive      Positive     Positive\n",
       "5          6       Mixed       Mixed       Mixed         Mixed        Mixed\n",
       "6          7    Positive    Positive     Neutral      Positive     Positive\n",
       "7          8     Neutral     Neutral     Neutral       Neutral      Neutral\n",
       "8          9    Positive    Positive    Positive      Positive     Positive\n",
       "9         10    Negative    Negative       Mixed      Negative     Negative"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Majority voting implementation\n",
    "def majority_vote(annotations):\n",
    "    \"\"\"\n",
    "    Return the most common label from a list of annotations.\n",
    "    \"\"\"\n",
    "    from collections import Counter\n",
    "    counts = Counter(annotations)\n",
    "    return counts.most_common(1)[0][0]\n",
    "\n",
    "# Apply majority voting\n",
    "final_labels = []\n",
    "for i in range(len(annotator1)):\n",
    "    annotations = [annotator1[i], annotator2[i], annotator3[i]]\n",
    "    final_labels.append(majority_vote(annotations))\n",
    "\n",
    "annotations_df['majority_vote'] = final_labels\n",
    "print(\"Labels with Majority Vote:\")\n",
    "annotations_df[['review_id', 'annotator_1', 'annotator_2', 'annotator_3', 'majority_vote', 'ground_truth']].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 9.1: Identify Disagreements for Expert Review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels with Disagreements\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>annotator_1</th>\n",
       "      <th>annotator_2</th>\n",
       "      <th>annotator_3</th>\n",
       "      <th>disagreements</th>\n",
       "      <th>ground_truth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>False</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>Mixed</td>\n",
       "      <td>Mixed</td>\n",
       "      <td>Mixed</td>\n",
       "      <td>False</td>\n",
       "      <td>Mixed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Positive</td>\n",
       "      <td>False</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Negative</td>\n",
       "      <td>False</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>Mixed</td>\n",
       "      <td>Mixed</td>\n",
       "      <td>Mixed</td>\n",
       "      <td>False</td>\n",
       "      <td>Mixed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Negative</td>\n",
       "      <td>False</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>False</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Positive</td>\n",
       "      <td>False</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "      <td>False</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Mixed</td>\n",
       "      <td>Positive</td>\n",
       "      <td>True</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    review_id annotator_1 annotator_2 annotator_3  disagreements ground_truth\n",
       "10         11    Positive    Positive     Neutral          False     Positive\n",
       "11         12       Mixed       Mixed       Mixed          False        Mixed\n",
       "12         13     Neutral     Neutral    Positive          False     Positive\n",
       "13         14    Negative    Positive    Negative          False     Negative\n",
       "14         15       Mixed       Mixed       Mixed          False        Mixed\n",
       "15         16    Negative    Negative    Negative          False     Negative\n",
       "16         17    Positive    Positive     Neutral          False     Positive\n",
       "17         18    Negative    Negative    Positive          False     Negative\n",
       "18         19    Positive    Positive    Positive          False     Positive\n",
       "19         20     Neutral       Mixed    Positive           True      Neutral"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Identify reviews where all 3 annotators disagree (no majority)\n",
    "# These should be sent to an expert for adjudication\n",
    "\n",
    "# Your code here\n",
    "def all_disagree(annotation):\n",
    "    if len(annotation) == len(set(annotation)):\n",
    "        return annotation\n",
    "            \n",
    "disagreements = []\n",
    "for i in range(len(annotator1)):\n",
    "    annotations = [annotator1[i], annotator2[i], annotator3[i]]\n",
    "    disagreement = all_disagree(annotations)\n",
    "    if disagreement is not None:\n",
    "        disagreements.append(True)\n",
    "    else:\n",
    "        disagreements.append(False)\n",
    "        \n",
    "\n",
    "annotations_df['disagreements'] = disagreements\n",
    "print(\"Labels with Disagreements\")\n",
    "annotations_df[['review_id', 'annotator_1', 'annotator_2', 'annotator_3', 'disagreements', 'ground_truth']].tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 9.2: Implement Weighted Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Neutral'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Implement weighted voting where annotator votes are weighted by their accuracy\n",
    "# Annotator 1 accuracy: 85%, Annotator 2: 80%, Annotator 3: 75%\n",
    "\n",
    "def weighted_vote(annotations, weights):\n",
    "    \"\"\"\n",
    "    Return the label with highest weighted vote.\n",
    "    \n",
    "    Args:\n",
    "        annotations: List of labels from each annotator\n",
    "        weights: List of weights for each annotator\n",
    "    \n",
    "    Returns:\n",
    "        Label with highest weighted sum\n",
    "    \"\"\"\n",
    "    # Your code here\n",
    "    weighted = {}\n",
    "    for i in range(len(annotations)):\n",
    "        weighted[annotations[i]] = weighted.get(annotations[i], 0) + weights[i]\n",
    "    return max(weighted.items(), key=lambda item: item[1])[0]\n",
    "\n",
    "# Test your function\n",
    "we_annotations = [\"Positive\", \"Positive\", \"Neutral\"]\n",
    "we = [.45, .20, .75]\n",
    "\n",
    "weighted_vote(we_annotations, we)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 10: Quality Dashboard\n",
    "\n",
    "### Question 10.1: Create an Annotator Quality Dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annotator Accuracies:\n",
      "annotator_1: 90.00%\n",
      "annotator_2: 85.00%\n",
      "annotator_3: 65.00%\n",
      "\n",
      "Pairwise Kappa Scores:\n",
      "annotator_1 vs annotator_2: 0.7895\n",
      "annotator_1 vs annotator_3: 0.3878\n",
      "annotator_2 vs annotator_3: 0.3793\n",
      "\n",
      "Label Distribution per Annotator:\n",
      "\n",
      "annotator_1 label counts:\n",
      "annotator_1\n",
      "Positive    8\n",
      "Negative    5\n",
      "Neutral     4\n",
      "Mixed       3\n",
      "Name: count, dtype: int64\n",
      "\n",
      "annotator_2 label counts:\n",
      "annotator_2\n",
      "Positive    9\n",
      "Mixed       5\n",
      "Negative    4\n",
      "Neutral     2\n",
      "Name: count, dtype: int64\n",
      "\n",
      "annotator_3 label counts:\n",
      "annotator_3\n",
      "Positive    7\n",
      "Neutral     5\n",
      "Mixed       5\n",
      "Negative    3\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# TODO: Create a quality dashboard showing:\n",
    "# 1. Each annotator's accuracy vs ground truth\n",
    "# 2. Pairwise kappa scores\n",
    "# 3. Number of labels per category for each annotator\n",
    "\n",
    "# Your code here\n",
    "\n",
    "def get_dashboard(annotators_df):\n",
    "    # accuracy vs ground truth\n",
    "    accuracies = {}\n",
    "    for col in ['annotator_1', 'annotator_2', 'annotator_3']:\n",
    "        correct = sum(annotators_df[col] == annotators_df['ground_truth'])\n",
    "        accuracies[col] = correct / len(annotators_df)\n",
    "    print(\"Annotator Accuracies:\")\n",
    "    for annotator, acc in accuracies.items():\n",
    "        print(f\"{annotator}: {acc:.2%}\")\n",
    "    # pairwise kappa scores\n",
    "    kappa_scores = {}\n",
    "    annotator_cols = ['annotator_1', 'annotator_2', 'annotator_3']\n",
    "    for i in range(len(annotator_cols)):\n",
    "        for j in range(i+1, len(annotator_cols)):\n",
    "            col1 = annotator_cols[i]\n",
    "            col2 = annotator_cols[j]\n",
    "            kappa = cohen_kappa_score(annotators_df[col1], annotators_df[col2])\n",
    "            kappa_scores[f\"{col1} vs {col2}\"] = kappa\n",
    "    print(\"\\nPairwise Kappa Scores:\")\n",
    "    for pair, kappa in kappa_scores.items():\n",
    "        print(f\"{pair}: {kappa:.4f}\")\n",
    "    \n",
    "    # number of labels per category for each annotator\n",
    "    print(\"\\nLabel Distribution per Annotator:\")\n",
    "    for col in annotator_cols:\n",
    "        print(f\"\\n{col} label counts:\")\n",
    "        print(annotators_df[col].value_counts())\n",
    "get_dashboard(annotations_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Challenge Problems\n",
    "\n",
    "### Challenge 1: Krippendorff's Alpha\n",
    "\n",
    "Implement Krippendorff's Alpha, which handles missing data and ordinal categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.6590909090909087"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Challenge: Implement Krippendorff's Alpha\n",
    "# This metric handles:\n",
    "# - Any number of annotators\n",
    "# - Missing data\n",
    "# - Different types of data (nominal, ordinal, interval, ratio)\n",
    "\n",
    "from itertools import combinations\n",
    "\n",
    "# Your code here\n",
    "def krippendorffs_alpha(data, ):\n",
    "    # data cleaning\n",
    "    n_annotators, n_labels = len(data), len(data[0])   \n",
    "    \n",
    "    values = sorted(set(label for row in data for label in row if label is not None))\n",
    "    val_to_idx = {v: i for i, v in enumerate(values)}\n",
    "    n_values = len(values)\n",
    "    \n",
    "    # P_observed calculation\n",
    "    Po = 0.0\n",
    "    n_pairs = 0\n",
    "    for i in range(n_labels):\n",
    "        col = [data[j][i] for j in range(n_annotators) if data[j][i] is not None]\n",
    "        for a, b in combinations(col, 2):\n",
    "            if a != b:\n",
    "                Po += 1\n",
    "            n_pairs += 1\n",
    "    if n_pairs == 0:\n",
    "        return 1.0\n",
    "    Po /= n_pairs\n",
    "    \n",
    "    # P_expected calculation\n",
    "    freq = {v: 0 for v in values}\n",
    "    for row in data:\n",
    "        for v in row:\n",
    "            if v is not None:\n",
    "                freq[v] += 1\n",
    "                \n",
    "    N = sum(freq.values())\n",
    "    Pe = 0.0\n",
    "    for i in values:\n",
    "        for j in values:\n",
    "            if i != j:\n",
    "                Pe += freq[i] * freq[j] * (0 if i == j else 1)\n",
    "    Pe /= (N * (N - 1))\n",
    "    \n",
    "    if Pe == 0:\n",
    "        return 1.0\n",
    "    \n",
    "    return (Po - Pe) / (1 - Pe)\n",
    "\n",
    "annotations = [\n",
    "    [1, 2, 3, None, 2],\n",
    "    [1, 2, 2, 3,    2],\n",
    "    [1, 2, 3, 3, None]\n",
    "]\n",
    "\n",
    "krippendorffs_alpha(annotations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 2: Annotation Cost Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cost_usd': 10000, 'time_hours': 33.333333333333336, 'annotators_needed': 3}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Challenge: Build a function that estimates annotation cost\n",
    "# Input: number of items, task type, quality level (redundancy)\n",
    "# Output: estimated cost in USD and time in hours\n",
    "\n",
    "def estimate_annotation_cost(n_items, task_type, quality_level, domain='general'):\n",
    "    \"\"\"\n",
    "    Estimate the cost and time for an annotation project.\n",
    "    \n",
    "    Args:\n",
    "        n_items: Number of items to annotate\n",
    "        task_type: 'text_classification', 'ner', 'bbox', 'segmentation'\n",
    "        quality_level: 'low' (1 annotator), 'medium' (2), 'high' (3)\n",
    "        domain: 'general' or 'expert'\n",
    "    \n",
    "    Returns:\n",
    "        dict with cost_usd, time_hours, annotators_needed\n",
    "    \"\"\"\n",
    "    # Your code here\n",
    "    base_rates = {\n",
    "        'text_classification': 1,\n",
    "        'ner': 4,\n",
    "        'bbox': 5,\n",
    "        'segmentation': 6\n",
    "    }\n",
    "    base_times = {\n",
    "        'text_classification': 0.01,\n",
    "        'ner': 0.03,\n",
    "        'bbox': 0.05,\n",
    "        'segmentation': 0.08\n",
    "    }\n",
    "    annotators_needed = {\n",
    "        'low': 1,\n",
    "        'medium': 2,\n",
    "        'high': 3\n",
    "    }\n",
    "    return {\n",
    "        \"cost_usd\": n_items * base_rates[task_type],\n",
    "        \"time_hours\": n_items * base_times[task_type]/annotators_needed[quality_level],\n",
    "        \"annotators_needed\": annotators_needed[quality_level]\n",
    "    }\n",
    "\n",
    "# Test with:\n",
    "estimate_annotation_cost(10000, 'text_classification', 'high')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 3: Label Studio API Integration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read label studio API documentation here: https://api.labelstud.io/api-reference/introduction/getting-started"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Challenge: Write functions to interact with Label Studio API\n",
    "# - Create a project\n",
    "# - Import tasks\n",
    "# - Export annotations\n",
    "\n",
    "# Note: Requires running Label Studio locally\n",
    "# pip install label-studio\n",
    "# label-studio start\n",
    "\n",
    "import requests\n",
    "\n",
    "class LabelStudioClient:\n",
    "    def __init__(self, url='http://localhost:8080', api_key=None):\n",
    "        self.url = url\n",
    "        self.api_key = api_key\n",
    "        self.headers = {'Authorization': f'Token {api_key}'}\n",
    "    \n",
    "    def create_project(self, title, config):\n",
    "        \"\"\"Create a new annotation project.\"\"\"\n",
    "        payload = {\n",
    "            \"title\": title,\n",
    "            \"label_config\": config\n",
    "        }\n",
    "        response = requests.post(f\"{self.url}/api/projects/\", json=payload, headers=self.headers)\n",
    "        if not response.ok:\n",
    "            raise Exception(f\"Error creating project: {response.text}\")\n",
    "        return response.json()\n",
    "    \n",
    "    def import_tasks(self, project_id, tasks):\n",
    "        \"\"\"Import tasks to a project.\"\"\"\n",
    "        response = requests.post(f\"{self.url}/api/projects/{project_id}/import/\", json=tasks, headers=self.headers)\n",
    "        if not response.ok:\n",
    "            raise Exception(f\"Error importing tasks: {response.text}\")\n",
    "        return response.json()\n",
    "    \n",
    "    def export_annotations(self, project_id, tasks, preannotated_from_fields=None):\n",
    "        \"\"\"Export annotations from a project.\"\"\"\n",
    "        responses = requests.get(f\"{self.url}/api/projects/{project_id}/export/\", headers=self.headers)\n",
    "        if not responses.ok:\n",
    "            raise Exception(f\"Error exporting annotations: {responses.text}\")\n",
    "        return responses.json()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "In this lab, you learned:\n",
    "\n",
    "1. **Label Studio Setup**: Creating annotation interfaces with XML configs\n",
    "2. **Annotation Guidelines**: Writing clear, comprehensive guidelines with edge cases\n",
    "3. **Percent Agreement**: Simple but limited measure of annotator agreement\n",
    "4. **Cohen's Kappa**: Agreement metric that accounts for chance (2 annotators)\n",
    "5. **Fleiss' Kappa**: Extension for multiple annotators\n",
    "6. **IoU**: Measuring agreement for spatial annotations\n",
    "7. **Majority Voting**: Resolving disagreements between annotators\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "- **Kappa >= 0.8** is the target for production annotation tasks\n",
    "- Clear guidelines with examples reduce disagreements\n",
    "- Multiple annotators + adjudication = higher quality labels\n",
    "- Different metrics for different annotation types\n",
    "\n",
    "### Next Week\n",
    "\n",
    "Week 4: Optimizing Labeling with Active Learning, Weak Supervision, and LLMs!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
